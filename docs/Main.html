<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>Main - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableClusterMetricsUI":true,"useReactTableCreateView":false,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":true,"enableJobsAclsV2InUI":false,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"sqlAclsDisabledMap":{"spark.databricks.acl.enabled":"false","spark.databricks.acl.sqlOnly":"false"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableFindAndReplace":true,"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"enableMaxConcurrentRuns":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-4ccf711c90fd8d633b5629f18c840ae0a337b85583bb20438c73de5a94f19099","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-08d9fc1551087e0876236f19640c4a83116b1649f15137427d21c9056656e80e","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-88f10af7324d00498d3cb8f6d808d32d5c60474845a5c264096b409ade4f25fb","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (3.3, GPU, Scala 2.11)","packageLabel":"spark-image-4ccf711c90fd8d633b5629f18c840ae0a337b85583bb20438c73de5a94f19099","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-3ef6d6cc156adc3024eaff9e47af444e30a5cc9e61d09c34e8ae9e1b0a4e4960","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (3.3 snapshot, Scala 2.10)","packageLabel":"spark-image-09756b249790a7c8ef49f9bfe143f5a659e69a3515b703d654db5e92a08a2883","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"latest-rc-scala2.11","displayName":"Latest RC (3.3, Scala 2.11)","packageLabel":"spark-image-8a04b8efdccbf114de89078cbdea89452111fbdb6f89fbed9f128e5b778d6e95","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"latest-stable-scala2.11","displayName":"Latest stable (3.3, Scala 2.11)","packageLabel":"spark-image-d9361b34430b88997c4e8d9bb3e2003e77cfbd7af75948968fdb30a40338cd43","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"latest-rc-scala2.10","displayName":"Latest RC (3.3, Scala 2.10)","packageLabel":"spark-image-09756b249790a7c8ef49f9bfe143f5a659e69a3515b703d654db5e92a08a2883","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"latest-stable-scala2.10","displayName":"Latest stable (3.3, Scala 2.10)","packageLabel":"spark-image-88f10af7324d00498d3cb8f6d808d32d5c60474845a5c264096b409ade4f25fb","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (3.3 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-5feb7cda877fd9b391835ad1b430973dcb675bd52e8acc83bd3b663e3960fc4a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-67ab3a06d1e83d5b60df7063245eb419a2e9fe329aeeb7e7d9713332c669bb17","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-0e50da7a73d3bc76fcca8ac8a67c1e036c5a30deb5663adf6d0f332cc8ec2c90","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-0c03d5f78139022c37032b5f3ffac5b5a4445d9cab8733e333f16a67a47262f9","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-d9361b34430b88997c4e8d9bb3e2003e77cfbd7af75948968fdb30a40338cd43","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (3.3 snapshot, Scala 2.11)","packageLabel":"spark-image-8a04b8efdccbf114de89078cbdea89452111fbdb6f89fbed9f128e5b778d6e95","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-aca37a44b05c9c0177ca8a639ad186ebace4aac1a7bdcf73829945ab47414f41","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-d549f2d4a523994ecdf37e531b51d5ec7d8be51534bb0ca5322eaad28ba8f557","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (3.3 GPU, Scala 2.11)","packageLabel":"spark-image-5feb7cda877fd9b391835ad1b430973dcb675bd52e8acc83bd3b663e3960fc4a","upgradable":true,"deprecated":false,"customerVisible":false}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"r4.xlarge":1,"m4.4xlarge":3,"r4.16xlarge":16,"Standard_DS11":0.5,"p2.8xlarge":16,"m4.10xlarge":8,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"m4.xlarge":0.75,"r4.8xlarge":8,"r4.large":0.5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"i3.large":0.75,"memory-optimized":1,"m4.large":0.375,"p2.16xlarge":24,"i3.8xlarge":8,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1.5,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"i3.2xlarge":2,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.55","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"enableNotebookCommandMode":true,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-aca37a44b05c9c0177ca8a639ad186ebace4aac1a7bdcf73829945ab47414f41","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":180,"useDevTierHomePage":true,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"enableStructuredDataAcls":false,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"7e487e8906bd141e3032c363a823d3c48d1535b5","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":false,"allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"enableClusterTagsUIByTier":false,"enableNotebookHistoryUI":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"enableEBSVolumesUIByTier":false,"singleSignOnComingSoon":false,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":2044923475617513,"name":"Main","language":"scala","commands":[{"version":"CommandV1","origId":622260859880138,"guid":"7c8df720-9748-4394-a885-99ce4b24d4cb","subtype":"command","commandType":"auto","position":0.5,"command":"%md # Modified Yahoo Streaming Benchmarks\n\nThis notebook can be used to run the benchmarks. Please make sure that the notebooks `Kafka Streams`, `Flink`, `Spark`, and `Utils`\nare in the same folder as this notebook. If you're running this benchmark on CE, clicking `Run All` above should be enough to run this benchmark after the requirements below are fulfilled.\n\n### Requirements\n\nBefore running any code, please make sure the following libraries are attached to your cluster:\n\n  1. org.apache.flink:flink-connector-kafka-0.10\\_2.11:1.2.1\n  2. org.apache.flink:flink-streaming-scala\\_2.11:1.2.1\n  3. org.apache.kafka:kafka-streams:0.10.2.1\n  4. io.spray:spray-json\\_2.11:1.3.3\n\nYou may also use the Scala 2.10 versions of these libraries on a Scala 2.10 cluster. For details on library installation, please refer to the [docs](https://docs.databricks.com/user-guide/libraries.html#libraries-from-maven-pypi-or-spark-packages).","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1504122146796,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"488eeeee-47b9-4589-bffb-13cf53675ad0"},{"version":"CommandV1","origId":2044923475617515,"guid":"83e4ad5c-b168-4c83-913d-4b94110feff1","subtype":"command","commandType":"auto","position":1.0,"command":"%run \"./Kafka Streams\"","commandVersion":0,"state":"finished","results":null,"errorSummary":"The execution of this command did not finish successfully","error":null,"workflows":[],"startTime":1504122146803,"submitTime":1504122146803,"finishTime":1504122198641,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"12c06d07-576c-46f5-bd17-6641eaea0b3a"},{"version":"CommandV1","origId":5219763161922,"guid":"d5e0fd6f-785e-4387-b75f-ac026a3180ee","subtype":"script","commandType":"auto","position":1.0666666666666667,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6348789a-5206-4ae7-819f-2b104cc548f4"},{"version":"CommandV1","origId":5219763161923,"guid":"c3357276-7fa9-449c-9539-51628d9f9075","subtype":"script","commandType":"auto","position":1.1333333333333333,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                           ^\n&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                                         ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122188364,"submitTime":1497563459163,"finishTime":1504122190869,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6e29f404-c20d-4460-95fa-9fc487709dbc"},{"version":"CommandV1","origId":5219763161924,"guid":"0829249a-ccea-4d35-abcc-e06df04691d3","subtype":"script","commandType":"auto","position":1.2,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:52: error: not found: type SSHUtils\n    kafkaVersion: String = &quot;0.10.2.1&quot;) extends Serializable with SSHUtils {\n                                                                 ^\n&lt;console&gt;:83: error: not found: value generateSshKeys\n    generateSshKeys()\n    ^\n&lt;console&gt;:93: error: not found: value setupSSH\n    setupSSH(numExecutors)\n    ^\n&lt;console&gt;:96: error: not found: value ssh\n      ssh(ip, s&quot;bash /dbfs/$dbfsDir/install-kafka.sh&quot;)\n      ^\n&lt;console&gt;:99: error: not found: value ssh\n    ssh(zookeeper, s&quot;kafka/bin/zookeeper-server-start.sh -daemon kafka/config/zookeeper.properties&quot;)\n    ^\n&lt;console&gt;:102: error: not found: value ssh\n      ssh(host, s&quot;bash /dbfs/$dbfsDir/configure-kafka.sh $zookeeper $id $host&quot;)\n      ^\n&lt;console&gt;:103: error: not found: value ssh\n      ssh(host, s&quot;kafka/bin/kafka-server-start.sh -daemon kafka/config/server.properties&quot;)\n      ^\n&lt;console&gt;:110: error: not found: value ssh\n        ssh(ip, s&quot;sudo monit stop spark-slave&quot;)\n        ^\n&lt;console&gt;:116: error: not found: value ssh\n    ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --create --topic $topic --partitions $partitions &quot; +\n    ^\n&lt;console&gt;:122: error: not found: value ssh\n      ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --delete --topic $topic --zookeeper $zookeeper:2181&quot;)\n      ^\n</div>","error":null,"workflows":[],"startTime":1504122190875,"submitTime":1497563500345,"finishTime":1504122191752,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2a6ca8c0-b730-4116-9c6b-a97dd2091f5c"},{"version":"CommandV1","origId":5219763161925,"guid":"e8d7cfff-3e51-4465-bcef-b3cc2cff07ea","subtype":"script","commandType":"auto","position":1.2666666666666666,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:43: error: value length is not a member of scala.collection.immutable.Set[String]\n    if (executors.length == 1) {\n                  ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122191756,"submitTime":1497563507562,"finishTime":1504122193187,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"982cd07a-52f2-479d-a42c-dfdc2a23ced4"},{"version":"CommandV1","origId":5219763161926,"guid":"27f163b3-ce83-480c-ad3e-8f91b176c226","subtype":"script","commandType":"auto","position":1.3333333333333333,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:14: error: type mismatch;\n found   : _$1 where type _$1\n required: T\n  def parse[T: ClassTag](json: String): T = parser.readValue(json, classTag[T].runtimeClass)\n                                                            ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122193191,"submitTime":1496441711822,"finishTime":1504122193513,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d0ba08c0-c9bb-4281-984a-8364a891cdc2"},{"version":"CommandV1","origId":5219763161927,"guid":"f9e8f3fc-438c-4ea7-ab69-07c0abb03dfe","subtype":"script","commandType":"auto","position":1.4,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122193517,"submitTime":1496441714347,"finishTime":1504122193999,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d02e8eb0-6c1d-4263-b55b-53e42d7bd4d5"},{"version":"CommandV1","origId":5219763161928,"guid":"c0451776-30c4-4df0-9135-6614fc9e2e82","subtype":"script","commandType":"auto","position":1.4666666666666668,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122194003,"submitTime":1496437832537,"finishTime":1504122194561,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fb9def09-0523-4341-bedb-f974a8c1ca01"},{"version":"CommandV1","origId":5219763161929,"guid":"74ef082e-e46b-4042-b862-d853c20767cc","subtype":"script","commandType":"auto","position":1.5333333333333332,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:88: error: not found: value generateStream\n    generateStream(spark, campaigns, tuplesPerSecond, recordGenParallelism, rampUpTimeSeconds)\n    ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122194565,"submitTime":1497036075966,"finishTime":1504122195110,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"55be3962-38ab-48b0-88fe-e41cd7a44987"},{"version":"CommandV1","origId":5219763161930,"guid":"70033146-3a65-4648-9e9c-36f8de88464d","subtype":"script","commandType":"auto","position":1.6,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import scala.collection.JavaConverters._\nimport org.apache.spark.sql.SparkSession\nimport com.databricks.benchmark.yahoo.YahooBenchmarkRunner\ndefined trait Benchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:94: error: abstract member may not have private modifier\n         private def startReader(): Unit\n                     ^\n</div>","error":null,"workflows":[],"startTime":1504122195114,"submitTime":1496436911439,"finishTime":1504122195621,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1b0cbf94-0413-4f67-b76b-51702adad1a4"},{"version":"CommandV1","origId":5219763161931,"guid":"b7208a7d-7846-4899-82b0-8e44b29548e7","subtype":"script","commandType":"auto","position":1.6666666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import java.util.UUID\nimport org.apache.spark.sql.{DataFrame, Encoders}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport com.databricks.spark.LocalKafka\nimport com.databricks.benchmark.yahoo._\ndefined class YahooBenchmark\ndefined object YahooBenchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:90: error: not found: value CampaignAd\n           CampaignAd(UUID.randomUUID().toString, UUID.randomUUID().toString)\n           ^\n</div>","error":null,"workflows":[],"startTime":1504122195625,"submitTime":1496436926089,"finishTime":1504122196261,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7b6af53b-f8a6-4957-b99f-6e2529f3a3cc"},{"version":"CommandV1","origId":5219763161932,"guid":"6c08cef3-bafc-4240-b725-415678a4373c","subtype":"script","commandType":"auto","position":1.7333333333333334,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:23: error: class KafkaProducer takes type parameters\n  def getProducer(kafkaNodesString: String): KafkaProducer = {\n                                             ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122196265,"submitTime":1498012773328,"finishTime":1504122196567,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6518411f-f8ba-4311-bb40-a1bdb8514891"},{"version":"CommandV1","origId":5219763161933,"guid":"699dce53-1e16-465b-aafc-fff45c54209e","subtype":"script","commandType":"auto","position":1.8,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:30: error: type mismatch;\n found   : Null(null)\n required: T\n    if (data == null) return null\n                             ^\n&lt;driver&gt;:35: error: too many arguments for method println: (x: Any)Unit\n        println(s&quot;Error during ${T.getClass.getName} deserialization&quot;, e)\n               ^\n&lt;driver&gt;:36: error: type mismatch;\n found   : Null(null)\n required: T\n        null\n        ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122196571,"submitTime":1498013247811,"finishTime":1504122197072,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"81fffe8f-7408-4576-bc4e-7e554ceeba39"},{"version":"CommandV1","origId":5219763161934,"guid":"828f3c39-3586-4c68-b96f-90c48caad290","subtype":"script","commandType":"auto","position":1.8666666666666667,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n&lt;notebook&gt;:18: warning: imported `KStreamsUtils' is permanently hidden by definition of object KStreamsUtils in package kafka\nimport com.databricks.benchmark.kafka.KStreamsUtils\n                                      ^\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:16: warning: imported `KStreamsUtils' is permanently hidden by definition of object KStreamsUtils in package kafka\nimport com.databricks.benchmark.kafka.KStreamsUtils\n                                      ^\n&lt;driver&gt;:67: error: type mismatch;\n found   : org.apache.kafka.streams.kstream.ValueJoiner[com.databricks.benchmark.yahoo.ProjectedEvent,com.databricks.benchmark.yahoo.CampaignAd,com.databricks.benchmark.kafka.serializers.CampaignAndTimestamp]\n required: org.apache.kafka.streams.kstream.ValueJoiner[? &gt;: com.databricks.benchmark.yahoo.ProjectedEvent, ?, ? &lt;: String]\nNote: com.databricks.benchmark.kafka.serializers.CampaignAndTimestamp &gt;: ? &lt;: String, but Java-defined trait ValueJoiner is invariant in type VR.\nYou may wish to investigate a wildcard type such as `_ &gt;: ? &lt;: String`. (SLS 3.2.10)\n    val joined: KStream[String, String] = filteredEvents.join(kCampaigns, new ValueJoiner[ProjectedEvent, CampaignAd, CampaignAndTimestamp] {\n                                                                          ^\n&lt;driver&gt;:74: error: type mismatch;\n found   : org.apache.kafka.streams.kstream.KeyValueMapper[String,com.databricks.benchmark.kafka.serializers.CampaignAndTimestamp,String]\n required: org.apache.kafka.streams.kstream.KeyValueMapper[? &gt;: String, ? &gt;: String, ? &lt;: String]\nNote: com.databricks.benchmark.kafka.serializers.CampaignAndTimestamp &lt;: ? &gt;: String, but Java-defined trait KeyValueMapper is invariant in type V.\nYou may wish to investigate a wildcard type such as `_ &lt;: ? &gt;: String`. (SLS 3.2.10)\n      new KeyValueMapper[String, CampaignAndTimestamp, String] {\n      ^\n&lt;driver&gt;:73: error: type mismatch;\n found   : org.apache.kafka.streams.kstream.KStream[String,String]\n required: org.apache.kafka.streams.kstream.KStream[String,com.databricks.benchmark.kafka.serializers.CampaignAndTimestamp]\n    val keyedByCampaign: KStream[String, CampaignAndTimestamp] = joined.selectKey[String](\n                                                                                         ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122197078,"submitTime":1498013389919,"finishTime":1504122197849,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2063356d-e228-4a68-954d-ae5a2370e9a6"},{"version":"CommandV1","origId":5219763161935,"guid":"5b783fd8-1353-4e06-a196-c99ac5660bf7","subtype":"script","commandType":"auto","position":1.9333333333333333,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import com.databricks.benchmark.kafka.{KStreamsUtils, YahooBenchmarkUtils}\nimport com.databricks.benchmark.yahoo._\ndefined class KStreamsYahooRunner\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:75: error: the result type of an implicit conversion must be more specific than AnyRef\n             registerMethod.invoke(newAccum, sc, Some(&quot;kStreamsThroughput&quot;), true)\n                                                                             ^\n</div>","error":null,"workflows":[],"startTime":1504122197854,"submitTime":1497470650674,"finishTime":1504122198626,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["83e4ad5c-b168-4c83-913d-4b94110feff1"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ebbfb429-1d86-4c43-af27-6208ff6be739"},{"version":"CommandV1","origId":2044923475617529,"guid":"73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2","subtype":"command","commandType":"auto","position":2.0,"command":"%run \"./Flink\"","commandVersion":0,"state":"finished","results":null,"errorSummary":"The execution of this command did not finish successfully","error":null,"workflows":[],"startTime":1504122161504,"submitTime":1504122161504,"finishTime":1504122206636,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f25c0a19-b8ac-4747-8b74-a384b342eab0"},{"version":"CommandV1","origId":5219763161936,"guid":"2bf56125-9c76-4d13-b758-36052b0578a5","subtype":"script","commandType":"auto","position":2.066666666666667,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f8f7f89c-61b7-4afe-98bb-84087b0447c8"},{"version":"CommandV1","origId":5219763161937,"guid":"c7938b24-3b73-466c-a8b8-f8af243bb49c","subtype":"script","commandType":"auto","position":2.1333333333333333,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                           ^\n&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                                         ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122198629,"submitTime":1497563459163,"finishTime":1504122198921,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6e29f404-c20d-4460-95fa-9fc487709dbc"},{"version":"CommandV1","origId":5219763161938,"guid":"79b91386-cb3c-4761-acd5-df2b17b6d9a1","subtype":"script","commandType":"auto","position":2.2,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:52: error: not found: type SSHUtils\n    kafkaVersion: String = &quot;0.10.2.1&quot;) extends Serializable with SSHUtils {\n                                                                 ^\n&lt;console&gt;:83: error: not found: value generateSshKeys\n    generateSshKeys()\n    ^\n&lt;console&gt;:93: error: not found: value setupSSH\n    setupSSH(numExecutors)\n    ^\n&lt;console&gt;:96: error: not found: value ssh\n      ssh(ip, s&quot;bash /dbfs/$dbfsDir/install-kafka.sh&quot;)\n      ^\n&lt;console&gt;:99: error: not found: value ssh\n    ssh(zookeeper, s&quot;kafka/bin/zookeeper-server-start.sh -daemon kafka/config/zookeeper.properties&quot;)\n    ^\n&lt;console&gt;:102: error: not found: value ssh\n      ssh(host, s&quot;bash /dbfs/$dbfsDir/configure-kafka.sh $zookeeper $id $host&quot;)\n      ^\n&lt;console&gt;:103: error: not found: value ssh\n      ssh(host, s&quot;kafka/bin/kafka-server-start.sh -daemon kafka/config/server.properties&quot;)\n      ^\n&lt;console&gt;:110: error: not found: value ssh\n        ssh(ip, s&quot;sudo monit stop spark-slave&quot;)\n        ^\n&lt;console&gt;:116: error: not found: value ssh\n    ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --create --topic $topic --partitions $partitions &quot; +\n    ^\n&lt;console&gt;:122: error: not found: value ssh\n      ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --delete --topic $topic --zookeeper $zookeeper:2181&quot;)\n      ^\n</div>","error":null,"workflows":[],"startTime":1504122198926,"submitTime":1497563500345,"finishTime":1504122199319,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2a6ca8c0-b730-4116-9c6b-a97dd2091f5c"},{"version":"CommandV1","origId":5219763161939,"guid":"20a51a3b-288a-44dd-84e6-a1e97cd25ae6","subtype":"script","commandType":"auto","position":2.2666666666666666,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:43: error: value length is not a member of scala.collection.immutable.Set[String]\n    if (executors.length == 1) {\n                  ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122199326,"submitTime":1497563507562,"finishTime":1504122199767,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"982cd07a-52f2-479d-a42c-dfdc2a23ced4"},{"version":"CommandV1","origId":5219763161940,"guid":"f81d3a7c-9678-4d3b-b8bc-ae3fff6399ad","subtype":"script","commandType":"auto","position":2.3333333333333335,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:14: error: type mismatch;\n found   : _$1 where type _$1\n required: T\n  def parse[T: ClassTag](json: String): T = parser.readValue(json, classTag[T].runtimeClass)\n                                                            ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122199771,"submitTime":1496441711822,"finishTime":1504122199962,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d0ba08c0-c9bb-4281-984a-8364a891cdc2"},{"version":"CommandV1","origId":5219763161941,"guid":"086a59f1-43b7-45e8-8d33-47a8e7318bb6","subtype":"script","commandType":"auto","position":2.4,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122199966,"submitTime":1496441714347,"finishTime":1504122200163,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d02e8eb0-6c1d-4263-b55b-53e42d7bd4d5"},{"version":"CommandV1","origId":5219763161942,"guid":"2830aeb1-8bb8-450b-bc11-c39564e474f3","subtype":"script","commandType":"auto","position":2.466666666666667,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122200168,"submitTime":1496437832537,"finishTime":1504122200437,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fb9def09-0523-4341-bedb-f974a8c1ca01"},{"version":"CommandV1","origId":5219763161943,"guid":"e9656117-28da-499f-aa72-a4595580a5f2","subtype":"script","commandType":"auto","position":2.533333333333333,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:88: error: not found: value generateStream\n    generateStream(spark, campaigns, tuplesPerSecond, recordGenParallelism, rampUpTimeSeconds)\n    ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122200441,"submitTime":1497036075966,"finishTime":1504122200728,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"55be3962-38ab-48b0-88fe-e41cd7a44987"},{"version":"CommandV1","origId":5219763161944,"guid":"fd483f4f-6a4b-48c7-ba38-b3060f893551","subtype":"script","commandType":"auto","position":2.6,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import scala.collection.JavaConverters._\nimport org.apache.spark.sql.SparkSession\nimport com.databricks.benchmark.yahoo.YahooBenchmarkRunner\ndefined trait Benchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:94: error: abstract member may not have private modifier\n         private def startReader(): Unit\n                     ^\n</div>","error":null,"workflows":[],"startTime":1504122200733,"submitTime":1496436911439,"finishTime":1504122201319,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1b0cbf94-0413-4f67-b76b-51702adad1a4"},{"version":"CommandV1","origId":5219763161945,"guid":"4be7d365-5653-473c-b20d-ff8d98182c39","subtype":"script","commandType":"auto","position":2.6666666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import java.util.UUID\nimport org.apache.spark.sql.{DataFrame, Encoders}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport com.databricks.spark.LocalKafka\nimport com.databricks.benchmark.yahoo._\ndefined class YahooBenchmark\ndefined object YahooBenchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:90: error: not found: value CampaignAd\n           CampaignAd(UUID.randomUUID().toString, UUID.randomUUID().toString)\n           ^\n</div>","error":null,"workflows":[],"startTime":1504122201323,"submitTime":1496436926089,"finishTime":1504122202100,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7b6af53b-f8a6-4957-b99f-6e2529f3a3cc"},{"version":"CommandV1","origId":5219763161946,"guid":"0f7ff91b-4160-416c-b5fa-7e1b40e68dd7","subtype":"script","commandType":"auto","position":2.7333333333333334,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:37: error: type mismatch;\n found   : Int(0)\n required: java.sql.Timestamp\n      new WindowedCount(0, &quot;&quot;, 0, 0) // we don't need to deserialize JSON in Flink\n                        ^\n&lt;driver&gt;:37: error: type mismatch;\n found   : Int(0)\n required: java.sql.Timestamp\n      new WindowedCount(0, &quot;&quot;, 0, 0) // we don't need to deserialize JSON in Flink\n                                  ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122202105,"submitTime":1497560476829,"finishTime":1504122203221,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"f03444c4-d6ca-49ba-aa22-6777ccd7f4ea"},{"version":"CommandV1","origId":5219763161947,"guid":"564fa514-502e-4e69-9073-68faebbcb41b","subtype":"script","commandType":"auto","position":2.8,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\nwarning: there were three feature warnings; re-run with -feature for details\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:41: error: missing argument list for method generateElement in class EventGenerator\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `generateElement _` or `generateElement(_)` instead of `generateElement`.\n        sourceContext.collect(generateElement);\n                              ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122203226,"submitTime":1497560481304,"finishTime":1504122203784,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"03410bcd-d237-46ea-b11b-6b521baad68e"},{"version":"CommandV1","origId":5219763161948,"guid":"35517b5d-069e-4663-b5f9-0d12a4abd323","subtype":"script","commandType":"auto","position":2.8666666666666667,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n&lt;notebook&gt;:40: warning: method getKeyValueState in trait TriggerContext is deprecated: see corresponding Javadoc for more information.\n      val firstTimerSet = ctx.getKeyValueState(&quot;firstTimerSet&quot;, classOf[java.lang.Boolean], new java.lang.Boolean(false))\n                              ^\n&lt;notebook&gt;:89: warning: trait TimestampExtractor in package functions is deprecated: see corresponding Javadoc for more information.\n  class AdTimestampExtractor extends TimestampExtractor[(String, String, Timestamp)] {\n                                     ^\n&lt;notebook&gt;:140: warning: method assignTimestamps in class DataStream is deprecated\n      .assignTimestamps(new AdTimestampExtractor())\n       ^\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:39: warning: method getKeyValueState in trait TriggerContext is deprecated: see corresponding Javadoc for more information.\n      val firstTimerSet = ctx.getKeyValueState(&quot;firstTimerSet&quot;, classOf[java.lang.Boolean], new java.lang.Boolean(false))\n                              ^\n&lt;driver&gt;:65: error: class ThroughputLogger needs to be abstract, since method flatMap in trait FlatMapFunction of type (x$1: com.databricks.benchmark.yahoo.Event, x$2: org.apache.flink.util.Collector[Integer])Unit is not defined\n  class ThroughputLogger(logFreq: Long) extends FlatMapFunction[Event, Integer] {\n        ^\n&lt;driver&gt;:68: error: method flatMap overrides nothing.\nNote: the super classes of class ThroughputLogger contain the following, non final members named flatMap:\ndef flatMap(x$1: com.databricks.benchmark.yahoo.Event,x$2: org.apache.flink.util.Collector[Integer]): Unit\n    override def flatMap(element: Any, collector: Collector[Integer]): Unit = {\n                 ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122203787,"submitTime":1497560639042,"finishTime":1504122205216,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dc145070-991b-45e0-b695-691568866188"},{"version":"CommandV1","origId":5219763161949,"guid":"e6c068f9-bb5b-496d-9a3a-8fca42372f1c","subtype":"script","commandType":"auto","position":2.9333333333333336,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import com.databricks.spark.{LocalKafka, LocalFlink}\ndefined class FlinkYahooRunner\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:44: error: not found: type YahooBenchmarkRunner\n           logFreq: Int = 10000000) extends YahooBenchmarkRunner {\n                                            ^\n&lt;console&gt;:39: error: not found: type SparkSession\n           override val spark: SparkSession,\n                               ^\n&lt;console&gt;:51: error: not found: type CampaignAd\n             campaigns: Array[CampaignAd],\n                              ^\n&lt;console&gt;:63: error: not found: value Variables\n             &quot;--outputTopic&quot;, Variables.OUTPUT_TOPIC)\n                              ^\n&lt;console&gt;:75: error: not found: type DataFrame\n         override def getThroughput(): DataFrame = {\n                                       ^\n&lt;console&gt;:79: error: not found: type DataFrame\n         override def getLatency(): DataFrame = {\n                                    ^\n&lt;console&gt;:81: error: not found: value YahooBenchmark\n           val schema = YahooBenchmark.outputSchema.add(&quot;lastUpdate&quot;, TimestampType)\n                        ^\n</div>","error":null,"workflows":[],"startTime":1504122205221,"submitTime":1497559771095,"finishTime":1504122206629,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["73e9f676-e9d4-4a1c-9a65-f67cf5dd32f2"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"01cce013-954d-4a5f-852c-97f23e5248bd"},{"version":"CommandV1","origId":2044923475617543,"guid":"02a44417-32c8-4d65-80de-a9708e482a96","subtype":"command","commandType":"auto","position":3.0,"command":"%run \"./Spark\"","commandVersion":0,"state":"finished","results":null,"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122177153,"submitTime":1504122177153,"finishTime":1504122212148,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"318c011b-7b23-420f-8c73-1a127c317f06"},{"version":"CommandV1","origId":5219763161950,"guid":"99c01cbf-957e-4aa6-add7-db34329096fc","subtype":"script","commandType":"auto","position":3.0833333333333335,"command":"","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6696c7cf-498e-4951-a48d-f37e430f88bf"},{"version":"CommandV1","origId":5219763161951,"guid":"45cb77eb-1b7a-47fd-b927-8e441e41ec60","subtype":"script","commandType":"auto","position":3.1666666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                           ^\n&lt;driver&gt;:54: error: not found: value numExecutors\n    sc.parallelize(0 until numExecutors, numExecutors).foreach { i =&gt;\n                                         ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122206633,"submitTime":1497563459163,"finishTime":1504122207009,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6e29f404-c20d-4460-95fa-9fc487709dbc"},{"version":"CommandV1","origId":5219763161952,"guid":"a5d03a3b-a833-4265-96f9-1c40b2875c21","subtype":"script","commandType":"auto","position":3.25,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:52: error: not found: type SSHUtils\n    kafkaVersion: String = &quot;0.10.2.1&quot;) extends Serializable with SSHUtils {\n                                                                 ^\n&lt;console&gt;:83: error: not found: value generateSshKeys\n    generateSshKeys()\n    ^\n&lt;console&gt;:93: error: not found: value setupSSH\n    setupSSH(numExecutors)\n    ^\n&lt;console&gt;:96: error: not found: value ssh\n      ssh(ip, s&quot;bash /dbfs/$dbfsDir/install-kafka.sh&quot;)\n      ^\n&lt;console&gt;:99: error: not found: value ssh\n    ssh(zookeeper, s&quot;kafka/bin/zookeeper-server-start.sh -daemon kafka/config/zookeeper.properties&quot;)\n    ^\n&lt;console&gt;:102: error: not found: value ssh\n      ssh(host, s&quot;bash /dbfs/$dbfsDir/configure-kafka.sh $zookeeper $id $host&quot;)\n      ^\n&lt;console&gt;:103: error: not found: value ssh\n      ssh(host, s&quot;kafka/bin/kafka-server-start.sh -daemon kafka/config/server.properties&quot;)\n      ^\n&lt;console&gt;:110: error: not found: value ssh\n        ssh(ip, s&quot;sudo monit stop spark-slave&quot;)\n        ^\n&lt;console&gt;:116: error: not found: value ssh\n    ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --create --topic $topic --partitions $partitions &quot; +\n    ^\n&lt;console&gt;:122: error: not found: value ssh\n      ssh(kafkaNodes(0), s&quot;kafka/bin/kafka-topics.sh --delete --topic $topic --zookeeper $zookeeper:2181&quot;)\n      ^\n</div>","error":null,"workflows":[],"startTime":1504122207012,"submitTime":1497563500345,"finishTime":1504122207489,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2a6ca8c0-b730-4116-9c6b-a97dd2091f5c"},{"version":"CommandV1","origId":622260859880139,"guid":"f217729b-e89d-4a29-a34a-0ae1bfc15161","subtype":"command","commandType":"auto","position":3.25,"command":"%md ## Configurations\n\nFeel free to modify any of the confiugrations below. We provide two sets of configurations. One set is ideal for running single core \nimplementations on Community Edition, and the other can be used at scale. When used at scale, we recommend shutting down Spark on Kafka\nand Flink nodes to isolate each system as much as possible.\n\nAt Databricks, we ran the benchmarks at scale on:\n * 10 r3.xlarge instances for Kafka brokers (1 broker on an instance)\n * 11 r3.xlarge instances for Flink (1 node for the jobmanager, the rest for the taskmanagers, 4 task slots per instance)\n * 10 r3.xlarge worker instances for Spark\n\nWe use more Kafka brokers, and partitions (40) to give `Kafka Streams` equal parallelism with Spark and Flink.\nYou may also use c3.2xlarge instances and halve the number of instances, since c3.2xlarge's have double the CPUs of r3.xlarge.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1504122188154,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c6ba0687-a830-416c-9ef5-7e46affe678a"},{"version":"CommandV1","origId":5219763161953,"guid":"aabceec3-504b-40ad-bfcf-b3fa9e31d662","subtype":"script","commandType":"auto","position":3.3333333333333335,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:43: error: value length is not a member of scala.collection.immutable.Set[String]\n    if (executors.length == 1) {\n                  ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122207494,"submitTime":1497563507562,"finishTime":1504122208055,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"982cd07a-52f2-479d-a42c-dfdc2a23ced4"},{"version":"CommandV1","origId":5219763161954,"guid":"1fbfb774-d07a-421a-bcbf-7b1370c060d7","subtype":"script","commandType":"auto","position":3.4166666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:14: error: type mismatch;\n found   : _$1 where type _$1\n required: T\n  def parse[T: ClassTag](json: String): T = parser.readValue(json, classTag[T].runtimeClass)\n                                                            ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122208060,"submitTime":1496441711822,"finishTime":1504122208387,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d0ba08c0-c9bb-4281-984a-8364a891cdc2"},{"version":"CommandV1","origId":5219763161955,"guid":"08b10904-c7ee-4a71-8c33-4557ac0c65a4","subtype":"script","commandType":"auto","position":3.5,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122208391,"submitTime":1496441714347,"finishTime":1504122208656,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d02e8eb0-6c1d-4263-b55b-53e42d7bd4d5"},{"version":"CommandV1","origId":2044923475617549,"guid":"45857402-cf8e-4025-ae82-a4c40c48f087","subtype":"command","commandType":"auto","position":3.5,"command":"// Benchmark Configurations - Ideal for Community Edititon\nval stopSparkOnKafkaNodes = false\nval stopSparkOnFlinkNodes = false\nval numKafkaNodes = 1\nval numFlinkNodes = 1\nval flinkTaskSlots = 1 // Number of CPUs available for a taskmanager.\nval runDurationMillis = 100000 // How long to keep each stream running\nval numTrials = 3\nval benchmarkResultsBase = \"/streaming/benchmarks\" // Where to store the results of the benchmark\n\n//////////////////////////////////\n// Event Generation\n//////////////////////////////////\nval recordsPerSecond = 25000\nval rampUpTimeSeconds = 10 // Ramps up event generation to the specified rate for the given duration to allow the JVM to warm up\nval recordGenerationParallelism = 1 // Parallelism within Spark to generate data for the Kafka Streams benchmark\n\nval numCampaigns = 100 // The number of campaigns to generate events for. Configures the cardinality of the state that needs to be updated\n\nval kafkaEventsTopicPartitions = 1 // Number of partitions within Kafka for the `events` stream\nval kafkaOutputTopicPartitions = 1 // Number of partitions within Kafka for the `outout` stream. We write data out to Kafka instead of Redis\n\n//////////////////////////////////\n// Kafka Streams\n//////////////////////////////////\n// Total number of Kafka Streams applications that will be running.\nval kafkaStreamsNumExecutors = 1\n// Number of threads to use within each Kafka Streams application.\nval kafkaStreamsNumThreadsPerExecutor = 1\n\n//////////////////////////////////\n// Flink\n//////////////////////////////////\n// Parallelism to use in Flink. Needs to be <= numFlinkNodes * flinkTaskSlots\nval flinkParallelism = 1\n// We can have Flink emit updates for windows more frequently to reduce latency by sacrificing throughput. Setting this to 0 means that\n// we emit updates for windows according to the watermarks, i.e. we will emit the result of a window, once the watermark passes the end\n// of the window.\nval flinkTriggerIntervalMillis = 0\n// How often to log the throughput of Flink in #records. Setting this lower will give us finer grained results, but will sacrifice throughput\nval flinkThroughputLoggingFreq = 100000\n\n//////////////////////////////////\n// Spark\n//////////////////////////////////\nval sparkParallelism = 1","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">stopSparkOnKafkaNodes: Boolean = false\nstopSparkOnFlinkNodes: Boolean = false\nnumKafkaNodes: Int = 1\nnumFlinkNodes: Int = 1\nflinkTaskSlots: Int = 1\nrunDurationMillis: Int = 100000\nnumTrials: Int = 3\nbenchmarkResultsBase: String = /streaming/benchmarks\nrecordsPerSecond: Int = 25000\nrampUpTimeSeconds: Int = 10\nrecordGenerationParallelism: Int = 1\nnumCampaigns: Int = 100\nkafkaEventsTopicPartitions: Int = 1\nkafkaOutputTopicPartitions: Int = 1\nkafkaStreamsNumExecutors: Int = 1\nkafkaStreamsNumThreadsPerExecutor: Int = 1\nflinkParallelism: Int = 1\nflinkTriggerIntervalMillis: Int = 0\nflinkThroughputLoggingFreq: Int = 100000\nsparkParallelism: Int = 1\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122212142,"submitTime":1504122188177,"finishTime":1504122212889,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ada1b8ae-c770-400d-8cac-b56c587d82a0"},{"version":"CommandV1","origId":5219763161956,"guid":"fa28faef-0009-45a0-b2ab-23f738930c8e","subtype":"script","commandType":"auto","position":3.5833333333333335,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1504122208660,"submitTime":1496437832537,"finishTime":1504122209110,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fb9def09-0523-4341-bedb-f974a8c1ca01"},{"version":"CommandV1","origId":622260859880141,"guid":"f121c006-149d-4e52-bd62-47bbbdbe7ae0","subtype":"command","commandType":"auto","position":3.625,"command":"// // Benchmark Configurations - Larger Scale\n// val stopSparkOnKafkaNodes = true\n// val stopSparkOnFlinkNodes = true\n// val numKafkaNodes = 10\n// val numFlinkNodes = 10\n// val flinkTaskSlots = 4 // Number of CPUs available for a taskmanager.\n// val runDurationMillis = 100000 // How long to keep each stream running\n// val numTrials = 5\n// val benchmarkResultsBase = \"/streaming/benchmarks\" // Where to store the results of the benchmark\n\n// //////////////////////////////////\n// // Event Generation\n// //////////////////////////////////\n// val recordsPerSecond = 50000000\n// val rampUpTimeSeconds = 10 // Ramps up event generation to the specified rate for the given duration to allow the JVM to warm up\n// val recordGenerationParallelism = 1 // Parallelism within Spark to generate data for the Kafka Streams benchmark\n\n// val numCampaigns = 100 // The number of campaigns to generate events for. Configures the cardinality of the state that needs to be updated\n\n// val kafkaEventsTopicPartitions = 40 // Number of partitions within Kafka for the `events` stream\n// val kafkaOutputTopicPartitions = 40 // Number of partitions within Kafka for the `outout` stream. We write data out to Kafka instead of Redis\n\n// //////////////////////////////////\n// // Kafka Streams\n// //////////////////////////////////\n// // Total number of Kafka Streams applications that will be running.\n// val kafkaStreamsNumExecutors = 40\n// // Number of threads to use within each Kafka Streams application.\n// val kafkaStreamsNumThreadsPerExecutor = 1\n\n// //////////////////////////////////\n// // Flink\n// //////////////////////////////////\n// // Parallelism to use in Flink. Needs to be <= numFlinkNodes * flinkTaskSlots\n// val flinkParallelism = 40\n// // We can have Flink emit updates for windows more frequently to reduce latency by sacrificing throughput. Setting this to 0 means that\n// // we emit updates for windows according to the watermarks, i.e. we will emit the result of a window, once the watermark passes the end\n// // of the window.\n// val flinkTriggerIntervalMillis = 0\n// // How often to log the throughput of Flink in #records. Setting this lower will give us finer grained results, but will sacrifice throughput\n// val flinkThroughputLoggingFreq = 1000000\n\n// //////////////////////////////////\n// // Spark\n// //////////////////////////////////\n// val sparkParallelism = 40","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122212892,"submitTime":1504122188189,"finishTime":1504122213268,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6dd4697e-0814-42a8-8e28-3d961c045f6b"},{"version":"CommandV1","origId":5219763161957,"guid":"f6c71d88-e83c-4509-aede-502b042e597c","subtype":"script","commandType":"auto","position":3.6666666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Warning: classes defined within packages cannot be redefined without a cluster restart.\nCompilation successful.\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;driver&gt;:88: error: not found: value generateStream\n    generateStream(spark, campaigns, tuplesPerSecond, recordGenParallelism, rampUpTimeSeconds)\n    ^\nCompilation failed.</div>","error":null,"workflows":[],"startTime":1504122209113,"submitTime":1497036075966,"finishTime":1504122209413,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"55be3962-38ab-48b0-88fe-e41cd7a44987"},{"version":"CommandV1","origId":5219763161958,"guid":"5ddf5b1a-4312-4275-a3ff-372db2b39a62","subtype":"script","commandType":"auto","position":3.75,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import scala.collection.JavaConverters._\nimport org.apache.spark.sql.SparkSession\nimport com.databricks.benchmark.yahoo.YahooBenchmarkRunner\ndefined trait Benchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:94: error: abstract member may not have private modifier\n         private def startReader(): Unit\n                     ^\n</div>","error":null,"workflows":[],"startTime":1504122209416,"submitTime":1496436911439,"finishTime":1504122210097,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1b0cbf94-0413-4f67-b76b-51702adad1a4"},{"version":"CommandV1","origId":622260859880140,"guid":"5db1f914-573b-45c5-829d-12b0c35de5d0","subtype":"command","commandType":"auto","position":3.75,"command":"%md ## Benchmark","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1504122188201,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3f7016ec-f6fa-4a42-8eee-91a4e6d98341"},{"version":"CommandV1","origId":5219763161959,"guid":"0a92d086-903c-4011-955e-9ebcc8d71147","subtype":"script","commandType":"auto","position":3.8333333333333335,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">import java.util.UUID\nimport org.apache.spark.sql.{DataFrame, Encoders}\nimport org.apache.spark.sql.functions._\nimport org.apache.spark.sql.types._\nimport com.databricks.spark.LocalKafka\nimport com.databricks.benchmark.yahoo._\ndefined class YahooBenchmark\ndefined object YahooBenchmark\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:90: error: not found: value CampaignAd\n           CampaignAd(UUID.randomUUID().toString, UUID.randomUUID().toString)\n           ^\n</div>","error":null,"workflows":[],"startTime":1504122210102,"submitTime":1496436926089,"finishTime":1504122210944,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7b6af53b-f8a6-4957-b99f-6e2529f3a3cc"},{"version":"CommandV1","origId":5219763161960,"guid":"d2e3621d-f551-45ab-a7f9-9c70377d146b","subtype":"script","commandType":"auto","position":3.9166666666666665,"command":"","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">defined class SparkYahooRunner\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">&lt;console&gt;:120: error: value toDS is not a member of Array[com.databricks.benchmark.yahoo.CampaignAd]\n             .join(campaigns.toDS(), Seq(&quot;ad_id&quot;))\n                             ^\n</div>","error":null,"workflows":[],"startTime":1504122210948,"submitTime":1496437911735,"finishTime":1504122212139,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":["02a44417-32c8-4d65-80de-a9708e482a96"],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"dab3dea9-d9a3-429e-9991-36325465c886"},{"version":"CommandV1","origId":2044923475617555,"guid":"afc0a010-986f-4201-a160-1346616989ca","subtype":"command","commandType":"auto","position":4.0,"command":"val kafkaCluster = LocalKafka.setup(spark, stopSparkOnKafkaNodes = stopSparkOnKafkaNodes, numKafkaNodes = numKafkaNodes)\n\nval benchmark = new YahooBenchmark(\n  kafkaCluster,\n  tuplesPerSecond = recordsPerSecond,\n  recordGenParallelism = recordGenerationParallelism,\n  rampUpTimeSeconds = rampUpTimeSeconds,\n  kafkaEventsTopicPartitions = kafkaEventsTopicPartitions,\n  kafkaOutputTopicPartitions = kafkaOutputTopicPartitions,\n  numCampaigns = numCampaigns,\n  readerWaitTimeMs = runDurationMillis)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">kafkaCluster: com.databricks.spark.LocalKafka = com.databricks.spark.LocalKafka@163748e6\nbenchmark: YahooBenchmark = YahooBenchmark@32dd0bbf\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122213273,"submitTime":1504122188228,"finishTime":1504122213884,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ba5b80df-1df1-4b36-b8f0-979bbd482342"},{"version":"CommandV1","origId":2044923475617557,"guid":"c0a0686b-7cec-4125-8989-264328f55100","subtype":"command","commandType":"auto","position":7.0,"command":"val kStreamsRunner = new KStreamsYahooRunner(\n  spark,\n  numExecutors = kafkaStreamsNumExecutors,\n  numThreadsPerExecutor = kafkaStreamsNumThreadsPerExecutor,\n  kafkaCluster = kafkaCluster)\n\nbenchmark.run(kStreamsRunner, s\"$benchmarkResultsBase/kStreams\", numRuns = numTrials)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Wrote 160 bytes.\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 8.999450977 seconds\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\n[2017-08-30 19:43:44,826] ERROR java.lang.IllegalArgumentException: Topic measurements does not exist on ZK path 10.172.246.84:2181\n\tat kafka.admin.TopicCommand$.deleteTopic(TopicCommand.scala:166)\n\tat kafka.admin.TopicCommand$.main(TopicCommand.scala:68)\n\tat kafka.admin.TopicCommand.main(TopicCommand.scala)\n (kafka.admin.TopicCommand$)\nError while executing topic command : Topic measurements does not exist on ZK path 10.172.246.84:2181\nFAILED: command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;measurements&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nstarting reader took 5.00064756 seconds\nproducing records took 3.429747148 seconds\norg.apache.spark.SparkException: Job 401 cancelled part of cancelled job group kstreamsYahoo\nreader exiting\nrun 1 took 123.019741029 seconds\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 20.133015654 seconds\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic measurements is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nstarting reader took 5.010462357 seconds\nCreated topic &quot;measurements&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nproducing records took 2.455565075 seconds\norg.apache.spark.SparkException: Job 471 cancelled part of cancelled job group kstreamsYahoo\nreader exiting\nrun 2 took 133.413128652 seconds\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 20.343934085 seconds\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic measurements is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic measurements --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nstarting reader took 5.00290666 seconds\nproducing records took 1.15388355 seconds\nCreated topic &quot;measurements&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic measurements --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\norg.apache.spark.SparkException: Job 486 cancelled part of cancelled job group kstreamsYahoo\nreader exiting\nrun 3 took 133.881924263 seconds\nkStreamsRunner: KStreamsYahooRunner = KStreamsYahooRunner@49f5e285\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122213887,"submitTime":1504122188240,"finishTime":1504122615776,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2e7af157-881b-4485-b84b-e8ef6c876c6a"},{"version":"CommandV1","origId":2044923475617558,"guid":"c24195fa-b25d-4208-bba9-194bb46c8fd0","subtype":"command","commandType":"auto","position":7.75,"command":"YahooBenchmark.getBenchmarkResults(s\"$benchmarkResultsBase/kStreams\")","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1,"2017-08-30T19:43:47.521Z","2017-08-30T19:45:29.005Z",101484,388080.0,3824.051081943952,18916,81171.0,81189.0,81189,55740.08585858586],[2,"2017-08-30T19:46:07.863Z","2017-08-30T19:47:46.523Z",98660,366187.0,3711.6055138860734,21259,149491.0,149501.0,149501,65312.25344352617],[3,"2017-08-30T19:48:25.051Z","2017-08-30T19:50:03.571Z",98520,371800.0,3773.853024766545,23467,142463.0,142471.0,142471,62459.22558922559]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"trial","type":"\"integer\"","metadata":"{}"},{"name":"start","type":"\"string\"","metadata":"{}"},{"name":"end","type":"\"string\"","metadata":"{}"},{"name":"totalDurationMillis","type":"\"long\"","metadata":"{}"},{"name":"recordsProcessed","type":"\"double\"","metadata":"{}"},{"name":"throughput","type":"\"double\"","metadata":"{}"},{"name":"latency_min","type":"\"long\"","metadata":"{}"},{"name":"latency_95","type":"\"double\"","metadata":"{}"},{"name":"latency_99","type":"\"double\"","metadata":"{}"},{"name":"latency_max","type":"\"long\"","metadata":"{}"},{"name":"latency_avg","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null,"datasetInfos":[{"name":"res29","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"trial","type":"integer","nullable":true,"metadata":{}},{"name":"start","type":"string","nullable":true,"metadata":{}},{"name":"end","type":"string","nullable":true,"metadata":{}},{"name":"totalDurationMillis","type":"long","nullable":true,"metadata":{}},{"name":"recordsProcessed","type":"double","nullable":true,"metadata":{}},{"name":"throughput","type":"double","nullable":true,"metadata":{}},{"name":"latency_min","type":"long","nullable":true,"metadata":{}},{"name":"latency_95","type":"double","nullable":true,"metadata":{}},{"name":"latency_99","type":"double","nullable":true,"metadata":{}},{"name":"latency_max","type":"long","nullable":true,"metadata":{}},{"name":"latency_avg","type":"double","nullable":true,"metadata":{}}]}}]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122615804,"submitTime":1504122188253,"finishTime":1504122621001,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8ed1edf0-3dd7-43ec-adf8-5223dc22c784"},{"version":"CommandV1","origId":2044923475617561,"guid":"cc28fe67-ce2a-4cbf-816a-f6d8e3b50ff1","subtype":"command","commandType":"auto","position":8.0,"command":"val sparkRunner = new SparkYahooRunner(\n  spark,\n  kafkaCluster = kafkaCluster,\n  parallelism = sparkParallelism)\n\nbenchmark.run(sparkRunner, s\"$benchmarkResultsBase/spark\", numRuns = numTrials)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Wrote 160 bytes.\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 20.845277014 seconds\nstarting reader took 5.000600295 seconds\nproducing records took 0.821370901 seconds\nrun 1 took 130.443257579 seconds\njava.lang.InterruptedException: sleep interrupted\njava.lang.Thread.sleep(Native Method)\nlinef0ad29e156a54d818a253185193aa11b95.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$SparkYahooRunner.start(command-2044923475617573:42)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.startReader(command-2044923475617479:50)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$$$16dab54cf2bc1e3139128622727cc$$$$$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$runOnce$2$$anon$1.run(command-2044923475617478:82)\nnull\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 18.889296839 seconds\nstarting reader took 5.003593852 seconds\nproducing records took 0.8610593 seconds\nrun 2 took 128.714058696 seconds\njava.lang.InterruptedException: sleep interrupted\njava.lang.Thread.sleep(Native Method)\nlinef0ad29e156a54d818a253185193aa11b95.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$SparkYahooRunner.start(command-2044923475617573:42)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.startReader(command-2044923475617479:50)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$$$16dab54cf2bc1e3139128622727cc$$$$$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$runOnce$2$$anon$1.run(command-2044923475617478:82)\nnull\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 20.620017946 seconds\nstarting reader took 5.000449489 seconds\nproducing records took 0.920101977 seconds\nrun 3 took 130.159980954 seconds\nsparkRunner: SparkYahooRunner = SparkYahooRunner@739ec737\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504122621022,"submitTime":1504122188265,"finishTime":1504123019341,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ab49a2f8-b0d1-46b2-94e6-fd19d3f2ccc2"},{"version":"CommandV1","origId":2044923475617562,"guid":"0a1f986b-b06e-4d1c-ab04-925cb1b8084d","subtype":"command","commandType":"auto","position":8.5,"command":"YahooBenchmark.getBenchmarkResults(s\"$benchmarkResultsBase/spark\")","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1,"2017-08-30T19:50:49.192Z","2017-08-30T19:52:28.635Z",99443,2400000,24134.428768239093,1270,3433.0,3433.0,3433,2108.242424242424],[2,"2017-08-30T19:53:00.036Z","2017-08-30T19:54:39.331Z",99295,2375000,23918.62631552445,1296,2028.0,2028.0,2028,1663.3777777777777],[3,"2017-08-30T19:55:13.586Z","2017-08-30T19:56:52.827Z",99241,2400000,24183.55316854929,1266,2725.0,2726.0,2726,1730.4123048668503]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"trial","type":"\"integer\"","metadata":"{}"},{"name":"start","type":"\"string\"","metadata":"{}"},{"name":"end","type":"\"string\"","metadata":"{}"},{"name":"totalDurationMillis","type":"\"long\"","metadata":"{}"},{"name":"recordsProcessed","type":"\"long\"","metadata":"{}"},{"name":"throughput","type":"\"double\"","metadata":"{}"},{"name":"latency_min","type":"\"long\"","metadata":"{}"},{"name":"latency_95","type":"\"double\"","metadata":"{}"},{"name":"latency_99","type":"\"double\"","metadata":"{}"},{"name":"latency_max","type":"\"long\"","metadata":"{}"},{"name":"latency_avg","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null,"datasetInfos":[{"name":"res32","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"trial","type":"integer","nullable":true,"metadata":{}},{"name":"start","type":"string","nullable":true,"metadata":{}},{"name":"end","type":"string","nullable":true,"metadata":{}},{"name":"totalDurationMillis","type":"long","nullable":true,"metadata":{}},{"name":"recordsProcessed","type":"long","nullable":true,"metadata":{}},{"name":"throughput","type":"double","nullable":true,"metadata":{}},{"name":"latency_min","type":"long","nullable":true,"metadata":{}},{"name":"latency_95","type":"double","nullable":true,"metadata":{}},{"name":"latency_99","type":"double","nullable":true,"metadata":{}},{"name":"latency_max","type":"long","nullable":true,"metadata":{}},{"name":"latency_avg","type":"double","nullable":true,"metadata":{}}]}}]},"errorSummary":"The spark context has been stopped or the cluster has been terminated. Please restart the cluster or attach this notebook to a different cluster.","error":null,"workflows":[],"startTime":1504123019366,"submitTime":1504122188278,"finishTime":1504123023255,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c2943d08-143d-44e1-b1eb-d481e0117175"},{"version":"CommandV1","origId":2044923475617559,"guid":"cf179334-bb03-4368-b00d-52de4fbfa91c","subtype":"command","commandType":"auto","position":9.0,"command":"val flinkCluster = LocalFlink.setup(\n  spark,\n  stopSparkOnFlinkNodes = stopSparkOnFlinkNodes,\n  numFlinkNodes = numFlinkNodes,\n  numTaskSlots = flinkTaskSlots)\n\nval flinkRunner = new FlinkYahooRunner(\n  spark,\n  flinkCluster = flinkCluster,\n  kafkaCluster = kafkaCluster,\n  parallelism = flinkParallelism,\n  triggerIntervalMs = flinkTriggerIntervalMillis,\n  logFreq = flinkThroughputLoggingFreq)\n\nbenchmark.run(flinkRunner, s\"$benchmarkResultsBase/flink\", numRuns = numTrials)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">/root/.ssh/id_rsa\nJob Manager: 10.172.246.84\nTask Managers: 10.172.246.84\nexecuting command - bash /dbfs/home/streaming/benchmark/install-flink.sh on host: 10.172.246.84\nSUCCESS: command - bash /dbfs/home/streaming/benchmark/install-flink.sh on host: 10.172.246.84\nWrote 160 bytes.\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 20.579113402 seconds\nstarting reader took 5.000615657 seconds\n\n------------------------------------------------------------\n The program finished with the following exception:\n\norg.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job was cancelled.\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:427)\n\tat org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:101)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:400)\n\tat org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66)\n\tat org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.scala:634)\n\tat com.databricks.benchmark.flink.YahooBenchmark$.main(&lt;notebook&gt;:165)\n\tat com.databricks.benchmark.flink.YahooBenchmark.main(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:528)\n\tat org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:419)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:339)\n\tat org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:831)\n\tat org.apache.flink.client.CliFrontend.run(CliFrontend.java:256)\n\tat org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1079)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1126)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1123)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext$1.run(HadoopSecurityContext.java:43)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:40)\n\tat org.apache.flink.client.CliFrontend.main(CliFrontend.java:1122)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply$mcV$sp(JobManager.scala:901)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\njava.lang.RuntimeException: Nonzero exit value: 1\nscala.sys.package$.error(package.scala:27)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.slurp(ProcessBuilderImpl.scala:132)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang$bang(ProcessBuilderImpl.scala:102)\ncom.databricks.spark.LocalFlink.runJob(&lt;notebook&gt;:200)\nlinef0ad29e156a54d818a253185193aa11b75.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.generateData(command-2044923475617508:34)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.produceRecords(command-2044923475617479:46)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2$$anonfun$run$2.apply$mcV$sp(command-2044923475617478:103)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.linef0ad29e156a54d818a253185193aa11b91$$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$timeIt(command-2044923475617478:56)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2.run(command-2044923475617478:102)\nnull\nrun 1 took 162.4058236 seconds\njava.lang.InterruptedException: sleep interrupted\njava.lang.Thread.sleep(Native Method)\nlinef0ad29e156a54d818a253185193aa11b75.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.start(command-2044923475617508:26)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.startReader(command-2044923475617479:50)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$$$16dab54cf2bc1e3139128622727cc$$$$$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$runOnce$2$$anon$1.run(command-2044923475617478:82)\nnull\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 19.379823485 seconds\nstarting reader took 5.004655143 seconds\n\n------------------------------------------------------------\n The program finished with the following exception:\n\norg.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job was cancelled.\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:427)\n\tat org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:101)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:400)\n\tat org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66)\n\tat org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.scala:634)\n\tat com.databricks.benchmark.flink.YahooBenchmark$.main(&lt;notebook&gt;:165)\n\tat com.databricks.benchmark.flink.YahooBenchmark.main(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:528)\n\tat org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:419)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:339)\n\tat org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:831)\n\tat org.apache.flink.client.CliFrontend.run(CliFrontend.java:256)\n\tat org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1079)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1126)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1123)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext$1.run(HadoopSecurityContext.java:43)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:40)\n\tat org.apache.flink.client.CliFrontend.main(CliFrontend.java:1122)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply$mcV$sp(JobManager.scala:901)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\njava.lang.RuntimeException: Nonzero exit value: 1\nscala.sys.package$.error(package.scala:27)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.slurp(ProcessBuilderImpl.scala:132)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang$bang(ProcessBuilderImpl.scala:102)\ncom.databricks.spark.LocalFlink.runJob(&lt;notebook&gt;:200)\nlinef0ad29e156a54d818a253185193aa11b75.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.generateData(command-2044923475617508:34)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.produceRecords(command-2044923475617479:46)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2$$anonfun$run$2.apply$mcV$sp(command-2044923475617478:103)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.linef0ad29e156a54d818a253185193aa11b91$$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$timeIt(command-2044923475617478:56)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2.run(command-2044923475617478:102)\nnull\nrun 2 took 157.449955362 seconds\njava.lang.InterruptedException: sleep interrupted\njava.lang.Thread.sleep(Native Method)\nlinef0ad29e156a54d818a253185193aa11b75.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.start(command-2044923475617508:26)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.startReader(command-2044923475617479:50)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$$$16dab54cf2bc1e3139128622727cc$$$$$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$runOnce$2$$anon$1.run(command-2044923475617478:82)\nnull\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic output is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic output --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;output&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic output --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic campaigns is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic campaigns --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;campaigns&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic campaigns --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nTopic events is marked for deletion.\nNote: This will have no impact if delete.topic.enable is not set to true.\nSUCCESS: command - kafka/bin/kafka-topics.sh --delete --topic events --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nexecuting command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\nCreated topic &quot;events&quot;.\nSUCCESS: command - kafka/bin/kafka-topics.sh --create --topic events --partitions 1 --replication-factor 1 --zookeeper 10.172.246.84:2181 on host: 10.172.246.84\ninitialization took 21.941696946 seconds\nstarting reader took 5.000562178 seconds\n\n------------------------------------------------------------\n The program finished with the following exception:\n\norg.apache.flink.client.program.ProgramInvocationException: The program execution failed: Job was cancelled.\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:427)\n\tat org.apache.flink.client.program.StandaloneClusterClient.submitJob(StandaloneClusterClient.java:101)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:400)\n\tat org.apache.flink.streaming.api.environment.StreamContextEnvironment.execute(StreamContextEnvironment.java:66)\n\tat org.apache.flink.streaming.api.scala.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.scala:634)\n\tat com.databricks.benchmark.flink.YahooBenchmark$.main(&lt;notebook&gt;:165)\n\tat com.databricks.benchmark.flink.YahooBenchmark.main(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:528)\n\tat org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:419)\n\tat org.apache.flink.client.program.ClusterClient.run(ClusterClient.java:339)\n\tat org.apache.flink.client.CliFrontend.executeProgram(CliFrontend.java:831)\n\tat org.apache.flink.client.CliFrontend.run(CliFrontend.java:256)\n\tat org.apache.flink.client.CliFrontend.parseParameters(CliFrontend.java:1079)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1126)\n\tat org.apache.flink.client.CliFrontend$2.call(CliFrontend.java:1123)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext$1.run(HadoopSecurityContext.java:43)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1657)\n\tat org.apache.flink.runtime.security.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:40)\n\tat org.apache.flink.client.CliFrontend.main(CliFrontend.java:1122)\nCaused by: org.apache.flink.runtime.client.JobCancellationException: Job was cancelled.\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply$mcV$sp(JobManager.scala:901)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat org.apache.flink.runtime.jobmanager.JobManager$$anonfun$handleMessage$1$$anonfun$applyOrElse$6.apply(JobManager.scala:853)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)\n\tat scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)\n\tat akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)\n\tat akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)\n\tat scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)\n\tat scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)\n\tat scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)\n\tat scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)\njava.lang.RuntimeException: Nonzero exit value: 1\nscala.sys.package$.error(package.scala:27)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.slurp(ProcessBuilderImpl.scala:132)\nscala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang$bang(ProcessBuilderImpl.scala:102)\ncom.databricks.spark.LocalFlink.runJob(&lt;notebook&gt;:200)\nlinef0ad29e156a54d818a253185193aa11b75.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.generateData(command-2044923475617508:34)\nlinef0ad29e156a54d818a253185193aa11b93.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.produceRecords(command-2044923475617479:46)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2$$anonfun$run$2.apply$mcV$sp(command-2044923475617478:103)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.linef0ad29e156a54d818a253185193aa11b91$$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$timeIt(command-2044923475617478:56)\nlinef0ad29e156a54d818a253185193aa11b91.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anon$2.run(command-2044923475617478:102)\nnull\nrun 3 took 150.833025351 seconds\nflinkCluster: com.databricks.spark.LocalFlink = com.databricks.spark.LocalFlink@4a7ffbff\nflinkRunner: FlinkYahooRunner = FlinkYahooRunner@578842fa\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"java.lang.RuntimeException: Nonzero exit value: 137","error":"<div class=\"ansiout\">\tat scala.sys.package$.error(package.scala:27)\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder.slurp(ProcessBuilderImpl.scala:132)\n\tat scala.sys.process.ProcessBuilderImpl$AbstractBuilder.$bang$bang(ProcessBuilderImpl.scala:102)\n\tat line212100defb1d4bf2901e408c3006af0777.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$FlinkYahooRunner.stop(command-2044923475617508:46)\n\tat line212100defb1d4bf2901e408c3006af0795.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.stopReader(command-2044923475617479:54)\n\tat line212100defb1d4bf2901e408c3006af0793.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.line212100defb1d4bf2901e408c3006af0793$$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$runOnce(command-2044923475617478:124)\n\tat line212100defb1d4bf2901e408c3006af0793.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply$mcV$sp(command-2044923475617478:66)\n\tat line212100defb1d4bf2901e408c3006af0793.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.line212100defb1d4bf2901e408c3006af0793$$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$timeIt(command-2044923475617478:56)\n\tat line212100defb1d4bf2901e408c3006af0793.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$$anonfun$run$1.apply$mcVI$sp(command-2044923475617478:65)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\n\tat line212100defb1d4bf2901e408c3006af0793.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$Benchmark$class.run(command-2044923475617478:64)\n\tat line212100defb1d4bf2901e408c3006af0795.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$YahooBenchmark.run(command-2044923475617479:15)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:14)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:135)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:137)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:139)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:141)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:143)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:145)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:147)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:149)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:151)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:153)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:155)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:157)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:159)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:161)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:163)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:165)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:167)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:169)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:171)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:173)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:175)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:177)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:179)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:181)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:183)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:185)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:187)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:189)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw$$iw.&lt;init&gt;(command-2044923475617559:191)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw$$iw.&lt;init&gt;(command-2044923475617559:193)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$$iw.&lt;init&gt;(command-2044923475617559:195)\n\tat line212100defb1d4bf2901e408c3006af07113.$read.&lt;init&gt;(command-2044923475617559:197)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$.&lt;init&gt;(command-2044923475617559:201)\n\tat line212100defb1d4bf2901e408c3006af07113.$read$.&lt;clinit&gt;(command-2044923475617559)\n\tat line212100defb1d4bf2901e408c3006af07113.$eval$.$print$lzycompute(&lt;notebook&gt;:7)\n\tat line212100defb1d4bf2901e408c3006af07113.$eval$.$print(&lt;notebook&gt;:6)\n\tat line212100defb1d4bf2901e408c3006af07113.$eval.$print(&lt;notebook&gt;)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:786)\n\tat scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1047)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:638)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:637)\n\tat scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\n\tat scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)\n\tat scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:637)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:569)\n\tat scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:565)\n\tat com.databricks.backend.daemon.driver.DriverILoop.execute(DriverILoop.scala:186)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply$mcV$sp(ScalaDriverLocal.scala:184)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:184)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal$$anonfun$repl$1.apply(ScalaDriverLocal.scala:184)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExitInternal$.trapExit(DriverLocal.scala:452)\n\tat com.databricks.backend.daemon.driver.DriverLocal$TrapExit$.apply(DriverLocal.scala:406)\n\tat com.databricks.backend.daemon.driver.ScalaDriverLocal.repl(ScalaDriverLocal.scala:184)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:231)\n\tat com.databricks.backend.daemon.driver.DriverLocal$$anonfun$execute$2.apply(DriverLocal.scala:212)\n\tat com.databricks.logging.UsageLogging$$anonfun$withAttributionContext$1.apply(UsageLogging.scala:176)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)\n\tat com.databricks.logging.UsageLogging$class.withAttributionContext(UsageLogging.scala:171)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:39)\n\tat com.databricks.logging.UsageLogging$class.withAttributionTags(UsageLogging.scala:209)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:39)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:212)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat com.databricks.backend.daemon.driver.DriverWrapper$$anonfun$tryExecutingCommand$2.apply(DriverWrapper.scala:589)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:584)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:488)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:391)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:348)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:215)\n\tat java.lang.Thread.run(Thread.java:748)</div>","workflows":[],"startTime":1504123023262,"submitTime":1504122188289,"finishTime":1504123543318,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"099f7771-a4f6-409e-838d-17a143c527a4"},{"version":"CommandV1","origId":2044923475617560,"guid":"f611d388-cae2-45a2-b1d2-cea84cf33753","subtype":"command","commandType":"auto","position":11.0,"command":"YahooBenchmark.getBenchmarkResults(s\"$benchmarkResultsBase/flink\")","commandVersion":0,"state":"finished","results":{"type":"table","data":[[1,"2017-08-30T19:58:13.197Z","2017-08-30T19:59:59.978Z",106781,1500000,14047.442897144623,1532,2221.0,2245.0,2245,1906.2572084481176],[2,"2017-08-30T20:01:04.199Z","2017-08-30T20:02:46.083Z",101884,1400000,13741.117349142161,1123,2121.0,2181.0,2181,1871.6624242424243],[3,"2017-08-30T20:03:44.295Z","2017-08-30T20:05:27.082Z",102787,2200000,21403.484876492163,1030,1346.0,1348.0,1348,1230.1067676767677]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"trial","type":"\"integer\"","metadata":"{}"},{"name":"start","type":"\"string\"","metadata":"{}"},{"name":"end","type":"\"string\"","metadata":"{}"},{"name":"totalDurationMillis","type":"\"long\"","metadata":"{}"},{"name":"recordsProcessed","type":"\"long\"","metadata":"{}"},{"name":"throughput","type":"\"double\"","metadata":"{}"},{"name":"latency_min","type":"\"long\"","metadata":"{}"},{"name":"latency_95","type":"\"double\"","metadata":"{}"},{"name":"latency_99","type":"\"double\"","metadata":"{}"},{"name":"latency_max","type":"\"long\"","metadata":"{}"},{"name":"latency_avg","type":"\"double\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null,"datasetInfos":[{"name":"res35","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"trial","type":"integer","nullable":true,"metadata":{}},{"name":"start","type":"string","nullable":true,"metadata":{}},{"name":"end","type":"string","nullable":true,"metadata":{}},{"name":"totalDurationMillis","type":"long","nullable":true,"metadata":{}},{"name":"recordsProcessed","type":"long","nullable":true,"metadata":{}},{"name":"throughput","type":"double","nullable":true,"metadata":{}},{"name":"latency_min","type":"long","nullable":true,"metadata":{}},{"name":"latency_95","type":"double","nullable":true,"metadata":{}},{"name":"latency_99","type":"double","nullable":true,"metadata":{}},{"name":"latency_max","type":"long","nullable":true,"metadata":{}},{"name":"latency_avg","type":"double","nullable":true,"metadata":{}}]}}]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1504123543547,"submitTime":1504122188304,"finishTime":1504123547038,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d0b8b697-282b-41dc-b620-2aa6862d9c46"}],"dashboards":[],"guid":"98e97640-b258-4c22-85d2-d043f54ae70e","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
<script>var tableOfContentsCell = {"version":"CommandV1","origId":0,"guid":"51be7142-83cc-4ba0-8c00-69321a10cb78","subtype":"command","commandType":"auto","position":0.0,"command":"%md [&lsaquo; Back to Table of Contents](index.html)","commandVersion":1,"state":"finished","results":{"type":"raw","data":"","arguments":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{}};</script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>